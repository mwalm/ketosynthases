{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b43e392-c871-4af6-bbdd-afd7253e983b",
   "metadata": {},
   "source": [
    "Hello!\n",
    "This is a generic scipt for extracting predictions for KS structures from pretrained models. Some information you will need to get this going:\n",
    "1. This notebook was written for Python 3.8.17 for use in a Linux environment.    \n",
    "2. Packages that must be installed prior to use are listed below. You can install these using pip in the terminal. \n",
    "   numpy==1.23.5\n",
    "   pandas==1.5.3\n",
    "   torch==2.0.1\n",
    "   scikit-learn==1.3.0\n",
    "   matplotlib==3.7.2\n",
    "   torch-geometric==2.3.1\n",
    "   graphein==1.7.0\n",
    "\n",
    "3. The input for this script is KS homodimers as .pdb files. You can generate these using colabfold elsewhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b307df-97ad-4b46-ae72-c4c44782ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Variables ###\n",
    "input_structures_folder = \"/path/to/structure/folder/\"  # Path to protein structure folder. Please ensure that only .pdb structures are contained in this file\n",
    "graph_storage_folder = \"/path/to/empty/graph/storage/\"  # Please designate an empty fold for storing graph structures\n",
    "model_path = \"20250621_DHvsER_model6.pth\"               # Trained model path. \n",
    "output_folder = \"/path/to/results/folder/\"              # Must end with \"/\"\n",
    "output_file_name = \"name.csv\"                           # Must end with \".csv\"\n",
    "num_cores = 7                                           # Number of CPU cores to use for graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da423e8-47f7-44a3-8d78-b6ea124c06d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files found: 1262\n",
      "Finished making graphs.\n"
     ]
    }
   ],
   "source": [
    "### Create graphs from protein structures ###\n",
    "\n",
    "import os\n",
    "from functools import partial\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import graphein\n",
    "from graphein.protein.edges.distance import add_k_nn_edges\n",
    "from graphein.protein.features.nodes.amino_acid import amino_acid_one_hot\n",
    "from graphein.ml import GraphFormatConvertor, ProteinGraphDataset\n",
    "\n",
    "# Load structure file paths\n",
    "paths = [os.path.join(input_structures_folder, f) \n",
    "         for f in os.listdir(input_structures_folder)]\n",
    "print(f\"Number of files found: {len(paths)}\")\n",
    "\n",
    "# Graphein config\n",
    "config = graphein.protein.ProteinGraphConfig(\n",
    "    edge_construction_functions=[partial(add_k_nn_edges, k=4, long_interaction_threshold=0)],\n",
    "    node_metadata_functions=[amino_acid_one_hot]\n",
    ")\n",
    "\n",
    "# Conversion config\n",
    "convertor = GraphFormatConvertor(\n",
    "    src_format=\"nx\", dst_format=\"pyg\", verbose=\"all_info\",\n",
    "    columns=[\"edge_index\", \n",
    "             \"amino_acid_one_hot\", \n",
    "             \"node_id\", \"chain_id\",\n",
    "             \"residue_name\", \n",
    "             \"residue_number\", \n",
    "             \"atom_type\", \n",
    "             \"element_symbol\",\n",
    "             \"coords\", \n",
    "             \"b_factor\", \n",
    "             \"kind\", \n",
    "             \"name\", \n",
    "             \"chain_ids\"]\n",
    ")\n",
    "\n",
    "# Build dataset\n",
    "dataset = ProteinGraphDataset(\n",
    "    root=graph_storage_folder, paths=paths,\n",
    "    graphein_config=config, graph_format_convertor=convertor,\n",
    "    num_cores=num_cores\n",
    ")\n",
    "\n",
    "# Convert to PyG Data objects\n",
    "data_list = []\n",
    "for g in dataset:\n",
    "    data = Data(\n",
    "        edge_index=g.edge_index,\n",
    "        node_id=g.node_id,\n",
    "        coords=g.coords,\n",
    "        name=g.name,\n",
    "        num_nodes=g.num_nodes,\n",
    "        x=g.amino_acid_one_hot.view(len(g.node_id), 20)  # reshape one-hot encoding\n",
    "    )\n",
    "    data_list.append(data)\n",
    "\n",
    "loader = DataLoader(data_list, batch_size=64)\n",
    "print(\"Finished making graphs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83af940b-97b9-4d0f-96bc-a27d317fe197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Class 0 Probability  Class 1 Probability           File Paths\n",
      "193              0.929503             0.070497  SeEryAIII.KS1_A135A\n",
      "1050             0.923521             0.076479  SeEryAIII.KS1_A135D\n",
      "171              0.924780             0.075220  SeEryAIII.KS1_A135E\n",
      "914              0.904220             0.095780  SeEryAIII.KS1_A135G\n",
      "778              0.935340             0.064660  SeEryAIII.KS1_A135I\n",
      "...                   ...                  ...                  ...\n",
      "648              0.969999             0.030001      SeEryAIII_Mod.2\n",
      "365              0.997945             0.002055       SeEryAII_Mod.1\n",
      "350              0.982858             0.017142       SeEryAII_Mod.2\n",
      "90               0.949354             0.050646        SeEryAI_Mod.1\n",
      "493              0.977907             0.022093        SeEryAI_Mod.2\n",
      "\n",
      "[1262 rows x 3 columns]\n",
      "Results saved to: /home/q31032mw/Dropbox (The University of Manchester)/Max/17_ML_Project/GitHub/01 Scripts/03 Graph Networks/05 SeEryAIII_KS1_Mutation/20250727_DHvsER_SeEry_predictions_mono_7.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "\n",
    "# Define a GNN model\n",
    "class MyGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.lin = Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x.float(), edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = global_max_pool(x, batch)\n",
    "        return F.softmax(self.lin(x), dim=1)\n",
    "\n",
    "# Load trained model\n",
    "input_dim, hidden_dim, output_dim = 20, 64, 2\n",
    "model = MyGNN(input_dim, hidden_dim, output_dim)\n",
    "model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device).eval()\n",
    "\n",
    "# Run predictions\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "        predictions.append(out.cpu().numpy())\n",
    "\n",
    "# Combine predictions\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Create results DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Class 0 Probability\": predictions[:, 0],\n",
    "    \"Class 1 Probability\": predictions[:, 1],\n",
    "    \"File Paths\": [os.path.splitext(os.path.basename(p))[0] for p in paths]\n",
    "})\n",
    "\n",
    "result_df = df.sort_values(by=\"File Paths\")\n",
    "\n",
    "# Save results\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "save_path = os.path.join(output_folder, output_file_name)\n",
    "result_df.to_csv(save_path, index=False)\n",
    "\n",
    "print(result_df)\n",
    "\n",
    "print(f\"Results saved to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
